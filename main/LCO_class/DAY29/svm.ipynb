{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katlic\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"0.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.data\n",
    "y = data.target\n",
    "img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.resize(img, (8,8), interpolation=cv2.INTER_AREA)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = SVC(C=5.0, gamma=0.22)\n",
    "s.fit(x,data.target)\n",
    "print(s.score(x,data.target))\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(img2.reshape(-1,1))\n",
    "scaler.transform(img2.reshape(-1,1).reshape(8,8))\n",
    "plt.imshow(scaler.transform(img2.reshape(-1,1).reshape(8,8)))\n",
    "output = scaler.transform(img2.reshape(-1,1).reshape(8,8)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output :  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Output : \",s.predict([1-output])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "# decision making tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Making Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "x = data.data\n",
    "y = data.target\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function Copied from Scikit Learn Confusion matrix Web Link\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hamspam.csv', index_col='Unnamed: 0')\n",
    "df.columns = ['Label', 'News']\n",
    "y = df.Label\n",
    "x = df.drop(['Label'], axis=1)\n",
    "x_train,y_train,x_test,y_test = train_test_split(x['News'],y, test_size=0.2, random_state = 42)\n",
    "count_vector_obj = CountVectorizer(stop_words=\"english\")\n",
    "count_train = count_vector_obj.fit_transform(x_train)\n",
    "count_test = count_vector_obj.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4453, 7520)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_test.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hamspam.csv', index_col='Unnamed: 0')\n",
    "df.columns = ['Label', 'News']\n",
    "y = df.Label\n",
    "x = df.drop(['Label'], axis=1)\n",
    "x_train,y_train,x_test,y_test = train_test_split(x['News'],y, test_size=0.2, random_state = 42)\n",
    "normal_vector_obj = TfidfVectorizer(stop_words=\"english\")\n",
    "normal_train = normal_vector_obj.fit_transform(x_train)\n",
    "normal_test = normal_vector_obj.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zhong',\n",
       " 'zindgi',\n",
       " 'zoe',\n",
       " 'zogtorius',\n",
       " 'zoom',\n",
       " 'zouk',\n",
       " 'zyada',\n",
       " 'èn',\n",
       " 'ú1',\n",
       " '〨ud']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_vector_obj.get_feature_names()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhong'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector_obj.get_feature_names()[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4453, 1114]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-489896f585b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \"\"\"\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4453, 1114]"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_test = tfidf_vectorizer.fit_transform(x_test)\n",
    "\n",
    "# Imported as sir's code from ProtectedText\n",
    "\n",
    "#function Copied from Scikit Learn Confusion matrix Web Link\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "clf = MultinomialNB(alpha=0.5)\n",
    "\n",
    "clf.fit(count_train, y_train)\n",
    "\n",
    "pred = clf.predict(count_test)\n",
    "\n",
    "pred.shape\n",
    "\n",
    "metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['spam', 'ham'])\n",
    "\n",
    "import itertools\n",
    "plot_confusion_matrix(cm,classes=['spam','ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
